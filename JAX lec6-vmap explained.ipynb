{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"JAX lec6-vmap explained.ipynb","provenance":[],"authorship_tag":"ABX9TyM/8khP11ZK2YvrDCJjX0/M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#JAX transform functions\n","##vmap()\n","Write your functions as if you were dealing with a single datapoint!"],"metadata":{"id":"EzVigHLOPZYV"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"4YBwng88PL8N","executionInfo":{"status":"ok","timestamp":1641907913184,"user_tz":-360,"elapsed":613,"user":{"displayName":"Monika Yesmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01725538247809880401"}}},"outputs":[],"source":["import jax.numpy as jnp\n","import numpy as np\n","from jax import jit, grad, vmap\n","from jax import random\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["seed = 0\n","key = random.PRNGKey(seed)\n","\n","W = random.normal(key, (150, 100))  # e.g. weights of a linear NN layer\n","batched_x = random.normal(key, (10, 100))  # e.g. a batch of 10 flattened images\n","\n","def apply_matrix(x):\n","    return jnp.dot(W, x)  # (150, 100) * (100, 10) -> (150, 10)"],"metadata":{"id":"phcZ8SPEPnc_","executionInfo":{"status":"ok","timestamp":1641908090481,"user_tz":-360,"elapsed":714,"user":{"displayName":"Monika Yesmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01725538247809880401"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["batched_x.T.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFjYoXh7WeqE","executionInfo":{"status":"ok","timestamp":1641908144184,"user_tz":-360,"elapsed":760,"user":{"displayName":"Monika Yesmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01725538247809880401"}},"outputId":"47038017-9c3c-45fa-ce25-236bcb14c3ac"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 10)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["apply_matrix(batched_x.T).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XmVzVM0RQk7N","executionInfo":{"status":"ok","timestamp":1641908156087,"user_tz":-360,"elapsed":493,"user":{"displayName":"Monika Yesmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01725538247809880401"}},"outputId":"10d0d23d-5f07-44f1-b19a-8da491f629e8"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(150, 10)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["@jit  # Note: we can arbitrarily compose JAX transforms! Here jit + vmap.\n","def vmap_batched_apply_matrix(batched_x):\n","    return vmap(apply_matrix)(batched_x)\n","\n","print('Auto-vectorized with vmap')\n","%timeit vmap_batched_apply_matrix(batched_x).block_until_ready()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H_pPeO4HQ4Y_","executionInfo":{"status":"ok","timestamp":1641908237522,"user_tz":-360,"elapsed":6759,"user":{"displayName":"Monika Yesmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01725538247809880401"}},"outputId":"21ac663a-b2e6-48da-c678-467ccf78b23b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Auto-vectorized with vmap\n","The slowest run took 190.40 times longer than the fastest. This could mean that an intermediate result is being cached.\n","10000 loops, best of 5: 86.7 Âµs per loop\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"QcBbkvMiRMHk"},"execution_count":null,"outputs":[]}]}